{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Intro to CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](../../images/2.png)\n",
    "\n",
    "![](../../images/3.png)\n",
    "\n",
    "![](../../images/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Transfer Learning and Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Deep Networks learn complex features extractor, but need lots of data to train it from scratch\n",
    "\n",
    "> What if we can reuse an existing features extractor for a new task?\n",
    "\n",
    "### Transfer Learning \n",
    "- need much less data to train (for training only final MLP)\n",
    "- It works if a domain of a new task is similar to ImageNet (__How to evaluate this similarity? Is there a quantifiable method?__)\n",
    "    - For Example:\n",
    "        - Will not work for human emotion classification since there's no human faces in ImageNet dataset\n",
    "        - In this case, we should partially reuse the ImageNet extractor by __FineTuning__\n",
    "\n",
    "### FineTuning\n",
    "\n",
    "- Instead of starting with a random initialization, initialize deeper layers with values from ImageNet\n",
    "- Propagate all gradients with smaller learning rate\n",
    "- __Keras has the weights of pre-trained VGG, Inception, ResNet architectures__\n",
    "- We can fine-tune a bunch of different architectures and make an ensemble out of them\n",
    "\n",
    "____\n",
    "\n",
    "![](../../images/5.png)\n",
    "\n",
    "\n",
    "____\n",
    "### Other tasks (explain in later notes)\n",
    "![](../../images/6.png)\n",
    "\n",
    "\n",
    "#### Unpooling Methods\n",
    "\n",
    "- Nearest neighbor unpooling\n",
    "\n",
    "![](../../images/7.png)\n",
    "\n",
    "- Max unpooling\n",
    "\n",
    "![](../../images/8.png)\n",
    "\n",
    "![](../../images/9.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep autoencoder 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../images/9.png)\n",
    "\n",
    "![](../../images/10.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix decomposition\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../images/11.png)\n",
    "\n",
    "![](../../images/12.png)\n",
    "\n",
    "\n",
    "> Question 1:\n",
    "\n",
    "What could possible go wrong with such autoencoder where the \"code\" is longer than the original data.\n",
    "\n",
    "- Autoencoder can't minimize MSE as efficiently as before\n",
    "\n",
    "- It is impossible to do backpropagation through such autoencoder\n",
    "\n",
    "- Autoencoder's computation graph is invalid\n",
    "\n",
    "- __Autoencoder can learn in such a way that doesn't produce good features__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse autoencoder -- use L1 on activations\n",
    "\n",
    "![](../../images/13.png)\n",
    "\n",
    "\n",
    "> Question 2:\n",
    "\n",
    "What happens when you regularize neural network weights with L1 regularization?\n",
    "\n",
    "L1 regularization means adding sum of absolute values of weights to the loss function.\n",
    "\n",
    "- __Some weights may end up being exactly zero__\n",
    "\n",
    "- Network tends to have smaller loss on training data\n",
    "\n",
    "- You can no longer train your network with backprop\n",
    "\n",
    "- Some weights may end up going to infinity\n",
    "\n",
    "#### Redundant autoencoder -- use dropout to remove some units\n",
    "\n",
    "\n",
    "![](../../images/14.png)\n",
    "\n",
    "\n",
    "#### Denoising autoencoder -- use dropout to remove some input data\n",
    "\n",
    "![](../../images/15.png)\n",
    "\n",
    "\n",
    "> Question 3:\n",
    "\n",
    "Which part of our autoencoder can be reused as a part of image classifier network?\n",
    "\n",
    "[Spoiler: technically, all of them can; Which one is more natural?]\n",
    "\n",
    "- Only the first layer of encoder\n",
    "\n",
    "- Several decoder layers, starting from the first one\n",
    "\n",
    "- Only the layer before the bottleneck\n",
    "\n",
    "- __Several encoder layers, starting from the first one__\n",
    "\n",
    "- Only the last decoder layer\n",
    "\n",
    "\n",
    "![](../../images/16.png)\n",
    "\n",
    "\n",
    "#### Takeaway:\n",
    "\n",
    "- Supervised pre-training \n",
    "    - Needs labels for similar problem\n",
    "    - Luckily, we have ImageNet and Model Zoo\n",
    "        - Alas, it's only good for popular problems\n",
    "\n",
    "- Unsupervised pre-training\n",
    "    - Needs no labels at all\n",
    "    - May learn irrelevant features\n",
    "        - eg: background sky color for object classification\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
