{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find duplicate questions on StackOverflow by their embeddings\n",
    "\n",
    "calculate a similarity for pieces of text to find duplicate questions from [StackOverflow](https://stackoverflow.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Libraries\n",
    "\n",
    "We will need the following libraries:\n",
    "- [StarSpace](https://github.com/facebookresearch/StarSpace) — a general-purpose model for efficient learning of entity embeddings from Facebook\n",
    "- [Gensim](https://radimrehurek.com/gensim/) — a tool for solving various NLP-related tasks (topic modeling, text representation, ...)\n",
    "- [Numpy](http://www.numpy.org) — a package for scientific computing.\n",
    "- [scikit-learn](http://scikit-learn.org/stable/index.html) — a tool for data mining and data analysis.\n",
    "- [Nltk](http://www.nltk.org) — a platform to work with human language data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The following cell will download all data required for this assignment into the folder `week3/data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/train.tsv is already downloaded.\n",
      "File data/validation.tsv is already downloaded.\n",
      "File data/test.tsv is already downloaded.\n",
      "File data/test_embeddings.tsv is already downloaded.\n",
      "Downloading GoogleNews-vectors-negative300.bin.gz (1.5G) for you, it will take a while...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1fb82a3e214ce3a307cbacaba08838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1647046227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed incomplete download\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f25c6788caa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_week3_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdownload_week3_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/Advanced_ML_HSE/NLP/notebooks/week3/common/download_utils.py\u001b[0m in \u001b[0;36mdownload_week3_resources\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading GoogleNews-vectors-negative300.bin.gz (1.5G) for you, it will take a while...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     download_file(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\",\n\u001b[0;32m---> 87\u001b[0;31m                   \"GoogleNews-vectors-negative300.bin.gz\")\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Advanced_ML_HSE/NLP/notebooks/week3/common/download_utils.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(url, file_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_notebook_failsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common.download_utils import download_week3_resources\n",
    "\n",
    "download_week3_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading\n",
    "We will create a grader instace below and use it to collect your answers. Note that these outputs will be stored locally inside grader and will be uploaded to platform only after running submiting function in the last part of this assignment. If you want to make partial submission, you can run that cell any time you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grader import Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = Grader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding\n",
    "\n",
    "To solve the problem, you will use two different models of embeddings:\n",
    "\n",
    " - [preferred] [Pre-trained word vectors](https://code.google.com/archive/p/word2vec/) from Google which were trained on a part of Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. `GoogleNews-vectors-negative300.bin.gz` will be downloaded in `download_week3_resources()`.\n",
    " - Representations using StarSpace on StackOverflow data sample. You will need to train them from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always easier to start with pre-trained embeddings. Unpack the pre-trained Goggle's vectors and upload them using the function [KeyedVectors.load_word2vec_format](https://radimrehurek.com/gensim/models/keyedvectors.html) from gensim library with the parameter *binary=True*. If the size of the embeddings is larger than the avaliable memory, you could load only a part of the embeddings by defining the parameter *limit* (recommended: 500000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_embeddings = gensim.models.KeyedVectors.load_word2vec_format(fname='/home/karen/Downloads/data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to work with Google's word2vec embeddings?\n",
    "\n",
    "Once you have loaded the representations, make sure you can access them. First, you can check if the loaded embeddings contain a word:\n",
    "    \n",
    "    'word' in wv_embeddings\n",
    "    \n",
    "Second, to get the corresponding embedding you can use the square brackets:\n",
    "\n",
    "    wv_embeddings['word']\n",
    " \n",
    "### Checking that the embeddings are correct \n",
    " \n",
    "To prevent any errors during the first stage, we can check that the loaded embeddings are correct. You can call the function *check_embeddings*, implemented below, which runs 3 tests:\n",
    "1. Find the most similar word for provided \"positive\" and \"negative\" words.\n",
    "2. Find which word from the given list doesn’t go with the others.\n",
    "3. Find the most similar word for the provided one.\n",
    "\n",
    "In the right case the function will return the string *These embeddings look good*. Othervise, you need to validate the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_embeddings(embeddings):\n",
    "    error_text = \"Something wrong with your embeddings ('%s test isn't correct).\"\n",
    "    most_similar = embeddings.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "    if len(most_similar) < 1 or most_similar[0][0] != 'queen':\n",
    "        return error_text % \"Most similar\"\n",
    "\n",
    "    doesnt_match = embeddings.doesnt_match(['breakfast', 'cereal', 'dinner', 'lunch'])\n",
    "    if doesnt_match != 'cereal':\n",
    "        return error_text % \"Doesn't match\"\n",
    "    \n",
    "    most_similar_to_given = embeddings.most_similar_to_given('music', ['water', 'sound', 'backpack', 'mouse'])\n",
    "    if most_similar_to_given != 'sound':\n",
    "        return error_text % \"Most similar to given\"\n",
    "    \n",
    "    return \"These embeddings look good.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These embeddings look good.\n"
     ]
    }
   ],
   "source": [
    "print(check_embeddings(wv_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From word to text embeddings\n",
    "\n",
    "**Task 1 (Question2Vec).** Usually, we have word-based embeddings, but for the task we need to create a representation for the whole question. It could be done in different ways. In our case we will use a **mean** of all word vectors in the question. Now you need to implement the function *question_to_vec*, which calculates the question representation described above. This function should work with the input text as is without any preprocessing.\n",
    "\n",
    "Note that there could be words without the corresponding embeddings. In this case, you can just skip these words and don't take them into account during calculating the result. If the question doesn't contain any known word with embedding, the function should return a zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        embeddings: dict where the key is a word and a value is its' embedding\n",
    "        dim: size of the representation\n",
    "\n",
    "        result: vector representation for the question\n",
    "    \"\"\"\n",
    "    if len(question) == 0:\n",
    "        return np.zeros(dim)\n",
    "    # both unk and known words\n",
    "    word_embed = np.array([embeddings[word] for word in question.split() if word in embeddings])\n",
    "    if len(word_embed) == 0:\n",
    "        # all unk words\n",
    "         word_embed = np.zeros(dim)\n",
    "    else:\n",
    "        word_embed = np.mean(word_embed, axis=0)\n",
    "    return word_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the basic correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_vec_tests():\n",
    "    if (np.zeros(300) != question_to_vec('', wv_embeddings)).any():\n",
    "        return \"You need to return zero vector for empty question.\"\n",
    "    if (np.zeros(300) != question_to_vec('thereisnosuchword', wv_embeddings)).any():\n",
    "        return \"You need to return zero vector for the question, which consists only unknown words.\"\n",
    "    if (wv_embeddings['word'] != question_to_vec('word', wv_embeddings)).any():\n",
    "        return \"You need to check the corectness of your function.\"\n",
    "    if ((wv_embeddings['I'] + wv_embeddings['am']) / 2 != question_to_vec('I am', wv_embeddings)).any():\n",
    "        return \"Your function should calculate a mean of word vectors.\"\n",
    "    if (wv_embeddings['word'] != question_to_vec('thereisnosuchword word', wv_embeddings)).any():\n",
    "        return \"You should not consider words which embeddings are unknown.\"\n",
    "    return \"Basic tests are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic tests are passed.\n"
     ]
    }
   ],
   "source": [
    "print(question_to_vec_tests())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can submit embeddings for the questions from the file *test_embeddings.tsv* to earn the points. In this task you don't need to transform the text of a question somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/karen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from util import array_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "Current answer for task Question2Vec is: 0.01929389126598835\n",
      "-0.02872721292078495\n",
      "0.0460561104118824\n",
      "0.0852593332529068\n",
      "0.0243055559694767\n",
      "-0...\n"
     ]
    }
   ],
   "source": [
    "question2vec_result = []\n",
    "i=0\n",
    "for question in open('/home/karen/Downloads/data/stackoverflow_qa/test_embeddings.tsv'):\n",
    "    question = question.strip()\n",
    "    answer = question_to_vec(question, wv_embeddings)\n",
    "    if i<10:\n",
    "        print(answer.shape)\n",
    "        i+=1\n",
    "    question2vec_result = np.append(question2vec_result, answer)\n",
    "\n",
    "grader.submit_tag('Question2Vec', array_to_string(question2vec_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01929389, -0.02872721,  0.04605611, ..., -0.11884562,\n",
       "        -0.01780192,  0.01442464]), (30000,))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question2vec_result, question2vec_result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a method to create a representation of any sentence and we are ready for the first evaluation. So, let's check how well our solution (Google's vectors + *question_to_vec*) will work.\n",
    "\n",
    "## Evaluation of text similarity\n",
    "\n",
    "We can imagine that if we use good embeddings, the cosine similarity between the duplicate sentences should be less than for the random ones. Overall, for each pair of duplicate sentences we can generate *R* random negative examples and find out the position of the correct duplicate.  \n",
    "\n",
    "For example, we have the question *\"Exceptions What really happens\"* and we are sure that another question *\"How does the catch keyword determine the type of exception that was thrown\"* is a duplicate. But our model doesn't know it and tries to find out the best option also among questions like *\"How Can I Make These Links Rotate in PHP\"*, *\"NSLog array description not memory address\"* and *\"PECL_HTTP not recognised php ubuntu\"*. __The goal of the model is to rank all these 4 questions (1 *positive* and *R* = 3 *negative*) in the way that the correct one is in the first place.__\n",
    "\n",
    "However, it is unnatural to count on that the best candidate will be always in the first place. So let us consider the place of the best candidate in the sorted list of candidates and formulate a metric based on it. We can fix some *K* — a reasonalble number of top-ranked elements and *N* — a number of queries (size of the sample).\n",
    "\n",
    "### Hits@K\n",
    "\n",
    "The first simple metric will be a number of correct hits for some *K*:\n",
    "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [dup_i \\in topK(q_i)]$$\n",
    "\n",
    "where $q_i$ is the i-th query, $dup_i$ is its duplicate, $topK(q_i)$ is the top K elements of the ranked sentences provided by our model and the operation $[dup_i \\in topK(q_i)]$ equals 1 if the condition is true and 0 otherwise (more details about this operation could be found [here](https://en.wikipedia.org/wiki/Iverson_bracket)).\n",
    "\n",
    "\n",
    "### DCG@K\n",
    "The second one is a simplified [DCG metric](https://en.wikipedia.org/wiki/Discounted_cumulative_gain):\n",
    "\n",
    "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le K] $$\n",
    "\n",
    "where $rank_{dup_i}$ is a position of the duplicate in the sorted list of the nearest sentences for the query $q_i$. According to this metric, the model gets a higher reward for a higher position of the correct answer. If the answer does not appear in topK at all, the reward is zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation examples\n",
    "\n",
    "Let's calculate the described metrics for the toy example introduced above. In this case $N$ = 1 and the correct candidate for $q_1$ is *\"How does the catch keyword determine the type of exception that was thrown\"*. Consider the following ranking of the candidates:\n",
    "1. *\"How Can I Make These Links Rotate in PHP\"*\n",
    "2. *\"How does the catch keyword determine the type of exception that was thrown\"*\n",
    "3. *\"NSLog array description not memory address\"*\n",
    "4. *\"PECL_HTTP not recognised php ubuntu\"*\n",
    "\n",
    "Using the ranking above, calculate *Hits@K* metric for *K = 1, 2, 4*: \n",
    " \n",
    "- [K = 1] $\\text{Hits@1} = \\frac{1}{1}\\sum_{i=1}^1 \\, [dup_i \\in top1(q_i)] = [dup_1 \\in top1(q_1)] = 0$ because the correct answer doesn't appear in the *top1* list.\n",
    "- [K = 2] $\\text{Hits@2} = \\frac{1}{1}\\sum_{i=1}^1 \\, [dup_i \\in top2(q_i)] = [dup_1 \\in top2(q_1)] = 1$ because $rank_{dup_1} = 2$.\n",
    "- [K = 4] $\\text{Hits@4} = \\frac{1}{1}\\sum_{i=1}^1 \\, [dup_i \\in top4(q_i)] = [dup_1 \\in top4(q_1)] = 1$\n",
    "\n",
    "Using the ranking above, calculate *DCG@K* metric for *K = 1, 2, 4*:\n",
    "\n",
    "- [K = 1] $\\text{DCG@1} = \\frac{1}{1} \\sum_{i=1}^1\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le 1] = \\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le 1] = 0$ because the correct answer doesn't appear in the top1 list.\n",
    "- [K = 2] $\\text{DCG@2} = \\frac{1}{1} \\sum_{i=1}^1\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le 2] = \\frac{1}{\\log_2{3}}$, because $rank_{dup_1} = 2$.\n",
    "- [K = 4] $\\text{DCG@4} = \\frac{1}{1} \\sum_{i=1}^1\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le 4] = \\frac{1}{\\log_2{3}}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks 2 and 3 (HitsCount and DCGScore).** Implement the functions *hits_count* and *dcg_score* as described above. Each function has two arguments: *dup_ranks* and *k*. *dup_ranks* is a list which contains *values of ranks* of duplicates. For example, *dup_ranks* is *[2]* for the example provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, False, False]), array([0, 0, 0]), 0.0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([2,3,4])<=1), (np.array([2,3,4])<=1).astype(int), (np.array([2,3,4])<=1).astype(int).sum()/len([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True, False, False]), array([1, 0, 0]), 0.3333333333333333)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([2,3,4])<=2), (np.array([2,3,4])<=2).astype(int), (np.array([2,3,4])<=2).astype(int).sum()/len([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True, False]), array([1, 1, 0]), 0.6666666666666666)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([2,3,4])<=3), (np.array([2,3,4])<=3).astype(int), (np.array([2,3,4])<=3).astype(int).sum()/len([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True]), array([1, 1, 1]), 1.0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([2,3,4])<=4), (np.array([2,3,4])<=4).astype(int), (np.array([2,3,4])<=4).astype(int).sum()/len([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list of duplicates' ranks; one rank per question; \n",
    "                   length is a number of questions which we are looking for duplicates; \n",
    "                   rank is a number from 1 to len(candidates of the question); \n",
    "                   e.g. [2, 3] means that the first duplicate has the rank 2, the second one is 3.\n",
    "        k: number of top-ranked elements (k in Hits@k metric)\n",
    "\n",
    "        result: return Hits@k value for current ranking\n",
    "    \"\"\"\n",
    "    hit = 0\n",
    "    boolean_check = (np.array(dup_ranks)<=k)\n",
    "    ranks = boolean_check.astype(int)\n",
    "    print('ranks', ranks)\n",
    "    hit = ranks.sum()/len(dup_ranks)\n",
    "    return hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code on the tiny examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hits():\n",
    "    # *Evaluation example*\n",
    "    # answers — dup_i\n",
    "    answers = [\"How does the catch keyword determine the type of exception that was thrown\"]\n",
    "    \n",
    "    # candidates_ranking — the ranked sentences provided by our model\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                           \"NSLog array description not memory address\",\n",
    "                           \"PECL_HTTP not recognised php ubuntu\"]]\n",
    "    # dup_ranks — position of the dup_i in the list of ranks +1\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    print('dup_ranks', dup_ranks)\n",
    "    # correct_answers — the expected values of the result for each k from 1 to 4\n",
    "    correct_answers = [0, 1, 1, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        print('k', k, 'c', correct, 'hits_count', hits_count(dup_ranks, k))\n",
    "        if not np.isclose(hits_count(dup_ranks, k), correct):\n",
    "            return \"Check the function.\"\n",
    "    \n",
    "    # Other tests\n",
    "    answers = [\"How does the catch keyword determine the type of exception that was thrown\", \n",
    "               \"Convert Google results object (pure js) to Python object\"]\n",
    "    \n",
    "    # The first test: both duplicates on the first position in ranked list\n",
    "    candidates_ranking = [[\"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                           \"How Can I Make These Links Rotate in PHP\"], \n",
    "                          [\"Convert Google results object (pure js) to Python object\",\n",
    "                           \"WPF- How to update the changes in list item of a list\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    print('dup_ranks', dup_ranks)\n",
    "    correct_answers = [1, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        print('k', k, 'c', correct, 'hits_count', hits_count(dup_ranks, k))\n",
    "        if not np.isclose(hits_count(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: both duplicates on the first position in ranked list).\"\n",
    "        \n",
    "    # The second test: one candidate on the first position, another — on the second\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\"], \n",
    "                          [\"Convert Google results object (pure js) to Python object\",\n",
    "                           \"WPF- How to update the changes in list item of a list\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    print('dup_ranks', dup_ranks)\n",
    "    correct_answers = [0.5, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        print('k', k, 'c', correct, 'hits_count', hits_count(dup_ranks, k))\n",
    "        if not np.isclose(hits_count(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: one candidate on the first position, another — on the second).\"\n",
    "\n",
    "    # The third test: both candidates on the second position\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\"], \n",
    "                          [\"WPF- How to update the changes in list item of a list\",\n",
    "                           \"Convert Google results object (pure js) to Python object\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    print('dup_ranks', dup_ranks)\n",
    "    correct_answers = [0, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        print('k', k, 'c', correct, 'hits_count', hits_count(dup_ranks, k))\n",
    "        if not np.isclose(hits_count(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: both candidates on the second position).\"\n",
    "\n",
    "    return \"Basic test are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dup_ranks [2]\n",
      "ranks [0]\n",
      "k 1 c 0 hits_count 0.0\n",
      "ranks [0]\n",
      "ranks [1]\n",
      "k 2 c 1 hits_count 1.0\n",
      "ranks [1]\n",
      "ranks [1]\n",
      "k 3 c 1 hits_count 1.0\n",
      "ranks [1]\n",
      "ranks [1]\n",
      "k 4 c 1 hits_count 1.0\n",
      "ranks [1]\n",
      "dup_ranks [1, 1]\n",
      "ranks [1 1]\n",
      "k 1 c 1 hits_count 1.0\n",
      "ranks [1 1]\n",
      "ranks [1 1]\n",
      "k 2 c 1 hits_count 1.0\n",
      "ranks [1 1]\n",
      "dup_ranks [2, 1]\n",
      "ranks [0 1]\n",
      "k 1 c 0.5 hits_count 0.5\n",
      "ranks [0 1]\n",
      "ranks [1 1]\n",
      "k 2 c 1 hits_count 1.0\n",
      "ranks [1 1]\n",
      "dup_ranks [2, 2]\n",
      "ranks [0 0]\n",
      "k 1 c 0 hits_count 0.0\n",
      "ranks [0 0]\n",
      "ranks [1 1]\n",
      "k 2 c 1 hits_count 1.0\n",
      "ranks [1 1]\n",
      "Basic test are passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_hits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list of duplicates' ranks; one rank per question; \n",
    "                   length is a number of questions which we are looking for duplicates; \n",
    "                   rank is a number from 1 to len(candidates of the question); \n",
    "                   e.g. [2, 3] means that the first duplicate has the rank 2, the second one is 3.\n",
    "        k: number of top-ranked elements (k in DCG@k metric)\n",
    "\n",
    "        result: return DCG@k value for current ranking\n",
    "    \"\"\"\n",
    "    return (1 / np.log2(1+np.array(dup_ranks)[np.array(dup_ranks)<=k])).sum()/len(dup_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dcg():\n",
    "    # *Evaluation example*\n",
    "    # answers — dup_i\n",
    "    answers = [\"How does the catch keyword determine the type of exception that was thrown\"]\n",
    "    \n",
    "    # candidates_ranking — the ranked sentences provided by our model\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                           \"NSLog array description not memory address\",\n",
    "                           \"PECL_HTTP not recognised php ubuntu\"]]\n",
    "    # dup_ranks — position of the dup_i in the list of ranks +1\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    \n",
    "    # correct_answers — the expected values of the result for each k from 1 to 4\n",
    "    correct_answers = [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(dcg_score(dup_ranks, k), correct):\n",
    "            return \"Check the function.\"\n",
    "    \n",
    "    # Other tests\n",
    "    answers = [\"How does the catch keyword determine the type of exception that was thrown\", \n",
    "               \"Convert Google results object (pure js) to Python object\"]\n",
    "\n",
    "    # The first test: both duplicates on the first position in ranked list\n",
    "    candidates_ranking = [[\"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                           \"How Can I Make These Links Rotate in PHP\"], \n",
    "                          [\"Convert Google results object (pure js) to Python object\",\n",
    "                           \"WPF- How to update the changes in list item of a list\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    correct_answers = [1, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(dcg_score(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: both duplicates on the first position in ranked list).\"\n",
    "        \n",
    "    # The second test: one candidate on the first position, another — on the second\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\"], \n",
    "                          [\"Convert Google results object (pure js) to Python object\",\n",
    "                           \"WPF- How to update the changes in list item of a list\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    correct_answers = [0.5, (1 + (1 / (np.log2(3)))) / 2]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(dcg_score(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: one candidate on the first position, another — on the second).\"\n",
    "        \n",
    "    # The third test: both candidates on the second position\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\"], \n",
    "                          [\"WPF- How to update the changes in list item of a list\",\n",
    "                           \"Convert Google results object (pure js) to Python object\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    correct_answers = [0, 1 / (np.log2(3))]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(dcg_score(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: both candidates on the second position).\"\n",
    "\n",
    "    return \"Basic test are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic test are passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_dcg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit results of the functions *hits_count* and *dcg_score* for the following examples to earn the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = [\n",
    "    [1],\n",
    "    [1, 2],\n",
    "    [2, 1],\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    [9, 5, 4, 2, 8, 10, 7, 6, 1, 3],\n",
    "    [4, 3, 5, 1, 9, 10, 7, 8, 2, 6],\n",
    "    [5, 1, 7, 6, 2, 3, 8, 9, 10, 4],\n",
    "    [6, 3, 1, 4, 7, 2, 9, 8, 10, 5],\n",
    "    [10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranks [1]\n",
      "ranks [1 0]\n",
      "ranks [1 1]\n",
      "ranks [0 1]\n",
      "ranks [1 1]\n",
      "ranks [1 0 0]\n",
      "ranks [1 1 0]\n",
      "ranks [1 1 1]\n",
      "ranks [1 0 0 0 0 0 0 0 0 0]\n",
      "ranks [1 1 0 0 0 0 0 0 0 0]\n",
      "ranks [1 1 1 0 0 0 0 0 0 0]\n",
      "ranks [1 1 1 1 0 0 0 0 0 0]\n",
      "ranks [1 1 1 1 1 0 0 0 0 0]\n",
      "ranks [1 1 1 1 1 1 0 0 0 0]\n",
      "ranks [1 1 1 1 1 1 1 0 0 0]\n",
      "ranks [1 1 1 1 1 1 1 1 0 0]\n",
      "ranks [1 1 1 1 1 1 1 1 1 0]\n",
      "ranks [1 1 1 1 1 1 1 1 1 1]\n",
      "ranks [0 0 0 0 0 0 0 0 1 0]\n",
      "ranks [0 0 0 1 0 0 0 0 1 0]\n",
      "ranks [0 0 0 1 0 0 0 0 1 1]\n",
      "ranks [0 0 1 1 0 0 0 0 1 1]\n",
      "ranks [0 1 1 1 0 0 0 0 1 1]\n",
      "ranks [0 1 1 1 0 0 0 1 1 1]\n",
      "ranks [0 1 1 1 0 0 1 1 1 1]\n",
      "ranks [0 1 1 1 1 0 1 1 1 1]\n",
      "ranks [1 1 1 1 1 0 1 1 1 1]\n",
      "ranks [1 1 1 1 1 1 1 1 1 1]\n",
      "ranks [0 0 0 1 0 0 0 0 0 0]\n",
      "ranks [0 0 0 1 0 0 0 0 1 0]\n",
      "ranks [0 1 0 1 0 0 0 0 1 0]\n",
      "ranks [1 1 0 1 0 0 0 0 1 0]\n",
      "ranks [1 1 1 1 0 0 0 0 1 0]\n",
      "ranks [1 1 1 1 0 0 0 0 1 1]\n",
      "ranks [1 1 1 1 0 0 1 0 1 1]\n",
      "ranks [1 1 1 1 0 0 1 1 1 1]\n",
      "ranks [1 1 1 1 1 0 1 1 1 1]\n",
      "ranks [1 1 1 1 1 1 1 1 1 1]\n",
      "ranks [0 1 0 0 0 0 0 0 0 0]\n",
      "ranks [0 1 0 0 1 0 0 0 0 0]\n",
      "ranks [0 1 0 0 1 1 0 0 0 0]\n",
      "ranks [0 1 0 0 1 1 0 0 0 1]\n",
      "ranks [1 1 0 0 1 1 0 0 0 1]\n",
      "ranks [1 1 0 1 1 1 0 0 0 1]\n",
      "ranks [1 1 1 1 1 1 0 0 0 1]\n",
      "ranks [1 1 1 1 1 1 1 0 0 1]\n",
      "ranks [1 1 1 1 1 1 1 1 0 1]\n",
      "ranks [1 1 1 1 1 1 1 1 1 1]\n",
      "ranks [0 0 1 0 0 0 0 0 0 0]\n",
      "ranks [0 0 1 0 0 1 0 0 0 0]\n",
      "ranks [0 1 1 0 0 1 0 0 0 0]\n",
      "ranks [0 1 1 1 0 1 0 0 0 0]\n",
      "ranks [0 1 1 1 0 1 0 0 0 1]\n",
      "ranks [1 1 1 1 0 1 0 0 0 1]\n",
      "ranks [1 1 1 1 1 1 0 0 0 1]\n",
      "ranks [1 1 1 1 1 1 0 1 0 1]\n",
      "ranks [1 1 1 1 1 1 1 1 0 1]\n",
      "ranks [1 1 1 1 1 1 1 1 1 1]\n",
      "ranks [0 0 0 0 0 0 0 0 0 1]\n",
      "ranks [0 0 0 0 0 0 0 0 1 1]\n",
      "ranks [0 0 0 0 0 0 0 1 1 1]\n",
      "ranks [0 0 0 0 0 0 1 1 1 1]\n",
      "ranks [0 0 0 0 0 1 1 1 1 1]\n",
      "ranks [0 0 0 0 1 1 1 1 1 1]\n",
      "ranks [0 0 0 1 1 1 1 1 1 1]\n",
      "ranks [0 0 1 1 1 1 1 1 1 1]\n",
      "ranks [0 1 1 1 1 1 1 1 1 1]\n",
      "ranks [1 1 1 1 1 1 1 1 1 1]\n",
      "Current answer for task HitsCount is: 1.0\n",
      "0.5\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1....\n"
     ]
    }
   ],
   "source": [
    "hits_results = []\n",
    "for example in test_examples:\n",
    "    for k in range(len(example)):\n",
    "        hits_results.append(hits_count(example, k + 1))\n",
    "grader.submit_tag('HitsCount', array_to_string(hits_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task DCGScore is: 1.0\n",
      "0.5\n",
      "0.8154648767857288\n",
      "0.5\n",
      "0.8154648767857288\n",
      "0.3333333333333333\n",
      "0.5436432511904858\n",
      "0.7103099178...\n"
     ]
    }
   ],
   "source": [
    "dcg_results = []\n",
    "for example in test_examples:\n",
    "    for k in range(len(example)):\n",
    "        dcg_results.append(dcg_score(example, k + 1))\n",
    "grader.submit_tag('DCGScore', array_to_string(dcg_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  First solution: pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with predefined train, validation and test corpora. All the files are tab-separated, but have a different format:\n",
    " - *train* corpus contains similar sentences at the same row.\n",
    " - *validation* corpus contains the following columns: *question*, *similar question*, *negative example 1*, *negative example 2*, ... \n",
    " - *test* corpus contains the following columns: *question*, *example 1*, *example 2*, ...\n",
    "\n",
    "Validation corpus will be used for the intermediate validation of models. The test data will be necessary for submitting the quality of your model in the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should upload *validation* corpus to evaluate current solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(line.strip().split('\\t'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = read_corpus(filename='/home/karen/Downloads/data/stackoverflow_qa/validation.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use cosine distance to rank candidate questions which you need to implement in the function *rank_candidates*. The function should return a sorted list of pairs *(initial position in candidates list, candidate)*. Index of some pair corresponds to its rank (the first is the best). For example, if the list of candidates was *[a, b, c]* and the most similar is *c*, then *a* and *b*, the function should return a list *[(2, c), (0, a), (1, b)]*.\n",
    "\n",
    "Pay attention, if you use the function *cosine_similarity* from *sklearn.metrics.pairwise* to calculate similarity because it works in a different way: most similar objects has greatest similarity. It's preferable to use a vectorized version of *cosine_similarity* function. Try to compute similarity at once and not use list comprehension. It should speed up your computations significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        candidates: a list of strings (candidates) which we want to rank\n",
    "        embeddings: some embeddings\n",
    "        dim: dimension of the current embeddings\n",
    "        \n",
    "        result: a list of pairs (initial position in the list, question)\n",
    "    \"\"\"\n",
    "    \n",
    "    question_e = [question_to_vec(question, embeddings, dim)]\n",
    "    candidates_e = [question_to_vec(i, embeddings, dim) for i in candidates]\n",
    "    # print(np.array(question_e).shape, np.array(candidates_e).shape)\n",
    "    similarity = cosine_similarity(question_e,candidates_e)\n",
    "    # sorted_candidates = sorted(dict(zip(similarity[0], candidates)).items(), reverse=True)\n",
    "    # return [(candidates.index(s[1]), s[1]) for s in sorted_candidates]\n",
    "    return [(index, candidates[index]) for index in np.argsort(similarity)[0][::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code on the tiny examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rank_candidates():\n",
    "    questions = ['converting string to list', 'Sending array via Ajax fails']\n",
    "    candidates = [['Convert Google results object (pure js) to Python object', \n",
    "                   'C# create cookie from string and send it',\n",
    "                   'How to use jQuery AJAX for an outside domain?'], \n",
    "                  ['Getting all list items of an unordered list in PHP', \n",
    "                   'WPF- How to update the changes in list item of a list', \n",
    "                   'select2 not displaying search results']]\n",
    "    results = [[(1, 'C# create cookie from string and send it'), \n",
    "                (0, 'Convert Google results object (pure js) to Python object'), \n",
    "                (2, 'How to use jQuery AJAX for an outside domain?')],\n",
    "               [(0, 'Getting all list items of an unordered list in PHP'), \n",
    "                (2, 'select2 not displaying search results'), \n",
    "                (1, 'WPF- How to update the changes in list item of a list')]]\n",
    "    for question, q_candidates, result in zip(questions, candidates, results):\n",
    "        ranks = rank_candidates(question, q_candidates, wv_embeddings, 300)\n",
    "        print(ranks)\n",
    "        if not np.all(ranks == result):\n",
    "            return \"Check the function.\"\n",
    "    return \"Basic tests are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'C# create cookie from string and send it'), (0, 'Convert Google results object (pure js) to Python object'), (2, 'How to use jQuery AJAX for an outside domain?')]\n",
      "[(0, 'Getting all list items of an unordered list in PHP'), (2, 'select2 not displaying search results'), (1, 'WPF- How to update the changes in list item of a list')]\n",
      "Basic tests are passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_rank_candidates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the quality of the current approach. Run the next two cells to get the results. Pay attention that calculation of similarity between vectors takes time and this calculation is computed approximately in 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_ranking = []\n",
    "for line in validation:\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranks [0 0 0 ... 0 0 1]\n",
      "DCG@   1: 0.214 | Hits@   1: 0.214\n",
      "ranks [0 0 1 ... 0 0 1]\n",
      "DCG@   5: 0.268 | Hits@   5: 0.316\n",
      "ranks [1 0 1 ... 0 0 1]\n",
      "DCG@  10: 0.285 | Hits@  10: 0.367\n",
      "ranks [1 0 1 ... 0 0 1]\n",
      "DCG@ 100: 0.323 | Hits@ 100: 0.557\n",
      "ranks [1 0 1 ... 1 0 1]\n",
      "DCG@ 500: 0.355 | Hits@ 500: 0.814\n",
      "ranks [1 1 1 ... 1 1 1]\n",
      "DCG@1000: 0.375 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to print a binary heap tree without recursion? How do you best convert a recursive function to an iterative one? How can i use ng-model with directive in angular js flash: drawing and erasing\n",
      "How to start PhoneStateListener programmatically? PhoneStateListener and service Java cast object[] to model WCF and What does this mean?\n",
      "jQuery: Show a div2 when mousenter over div1 is over when hover on div1 depenting on if it is on div2 or not it should act differently How to run selenium in google app engine/cloud? Python Comparing two lists of strings for similarities\n"
     ]
    }
   ],
   "source": [
    "for line in validation[:3]:\n",
    "    q, *examples = line\n",
    "    print(q, *examples[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = GOOD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_validation = []\n",
    "for line in validation:\n",
    "    prepared_validation = [text_prepare(i) for i in line]\n",
    "prepared_validation = np.array(prepared_validation)[:, np.newaxis].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_prepared_ranking = []\n",
    "for line in prepared_validation:\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings)\n",
    "    wv_prepared_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranks [0 0 0 ... 0 0 0]\n",
      "DCG@   1: 0.011 | Hits@   1: 0.011\n",
      "ranks [0 0 0 ... 0 0 0]\n",
      "DCG@   5: 0.061 | Hits@   5: 0.118\n",
      "ranks [0 0 0 ... 0 0 0]\n",
      "DCG@  10: 0.102 | Hits@  10: 0.247\n",
      "ranks [1 1 1 ... 1 1 1]\n",
      "DCG@ 100: 0.263 | Hits@ 100: 0.999\n",
      "ranks [1 1 1 ... 1 1 1]\n",
      "DCG@ 500: 0.263 | Hits@ 500: 1.000\n",
      "ranks [1 1 1 ... 1 1 1]\n",
      "DCG@1000: 0.263 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_prepared_ranking, k), \n",
    "                                              k, hits_count(wv_prepared_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, prepare also train and test data, because you will need it in the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_file(in_, out_):\n",
    "    out = open(out_, 'w')\n",
    "    for line in open(in_, encoding='utf8'):\n",
    "        line = line.strip().split('\\t')\n",
    "        new_line = [text_prepare(q) for q in line]\n",
    "        print(*new_line, sep='\\t', file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_file(\"/home/karen/Downloads/data/stackoverflow_qa/train.tsv\",\"/home/karen/Downloads/data/stackoverflow_qa/train_prepared.tsv\")\n",
    "prepare_file(\"/home/karen/Downloads/data/stackoverflow_qa/test.tsv\",\"/home/karen/Downloads/data/stackoverflow_qa/test_prepared.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prep  = read_corpus(\"/home/karen/Downloads/data/stackoverflow_qa/test_prepared.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4 (W2VTokenizedRanks).** For each question from prepared *test.tsv* submit the ranks of the candidates to earn the points. The calculations should take about 3-5 minutes. Pay attention that the function *rank_candidates* returns a ranking, while in this case you should find a position in this ranking. Ranks should start with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_string(arr):\n",
    "    return '\\n'.join(str(num) for num in arr)\n",
    "\n",
    "def matrix_to_string(matrix):\n",
    "    return '\\n'.join('\\t'.join(str(num) for num in line) for line in matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300) (100, 300)\n",
      "[(39, 'angularfire impossible recover time entered user database'), (22, 'get full description activity cleartool'), (67, 'importing another module another subdirectory current directorys parent directory python'), (60, 'minimize function selection function call overhead'), (99, 'doctrine preupdate invokes doesnt change related entity property prepersist'), (13, 'description item name paypal payment received email'), (2, 'development tools permission set'), (55, 'user input restriction goes haywire'), (3, 'go scene without using button flash asc3'), (74, 'problem jquery editinplace live function need ninja')]\n",
      "[39, 22, 67, 60, 99, 13, 2, 55, 3, 74]\n",
      "[94, 7, 9, 64, 37, 32, 93, 24, 100]\n",
      "(1, 300) (100, 300)\n",
      "[(8, 'notice compatible server client encryption algorithms found'), (6, 'authentication internal external users'), (15, 'choosing cloud storage service web api ftp third party server'), (30, 'use sorting algorithm java'), (43, 'aspnet core running windows service gets 500 internal server error'), (75, 'tool generate database schema xml schema'), (26, 'jquery natively support disable method'), (71, 'ms access bound time filed sql server'), (36, 'organizing code files xml files android sdk'), (92, 'windows phone 7 ftp client')]\n",
      "[8, 6, 15, 30, 43, 75, 26, 71, 36, 92]\n",
      "[37, 33, 16, 86, 70, 2, 39, 1, 94]\n",
      "(1, 300) (100, 300)\n",
      "[(55, 'symfony2 integrate php library bundle'), (18, 'using enterprise library logging application block nhibernate'), (9, 'setting entityframework 6 wcf data services 56'), (82, 'remove text logo add overflow android actionbar using appcompat api 8'), (64, 'return stored procedure data ms access table'), (45, 'choosing application server web application development'), (11, 'storing one class another array'), (17, 'access c# variable value javascript function net mvc3'), (37, 'disable texture case level unlock system unity'), (31, 'magento stores country full name')]\n",
      "[55, 18, 9, 82, 64, 45, 11, 17, 37, 31]\n",
      "[32, 12, 66, 45, 74, 29, 20, 43, 3]\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n",
      "(1, 300) (100, 300)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-ad1fe92ea8d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mranked_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mw2v_ranks_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mranked_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranked_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgrader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W2VTokenizedRanks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_ranks_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-174-ad1fe92ea8d2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mranked_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mw2v_ranks_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mranked_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranked_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgrader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W2VTokenizedRanks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_ranks_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w2v_ranks_results = []\n",
    "prepared_test_data = '/home/karen/Downloads/data/stackoverflow_qa/test_prepared.tsv'\n",
    "i=0\n",
    "for line in open(prepared_test_data):\n",
    "    q, *candidates = line.strip().split('\\t')\n",
    "    ranks = rank_candidates(q, candidates, wv_embeddings, 300)\n",
    "    ranked_candidates = [r[0] for r in ranks]\n",
    "    if i<3:\n",
    "        print(ranks[:10])\n",
    "        print([r[0] for r in ranks[:10]])\n",
    "        print([ranked_candidates.index(i) + 1 for i in range(1, 10)])\n",
    "        i+=1\n",
    "    w2v_ranks_results.append([ranked_candidates.index(i) + 1 for i in range(len(ranked_candidates))])\n",
    "    \n",
    "grader.submit_tag('W2VTokenizedRanks', matrix_to_string(w2v_ranks_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced solution: StarSpace embeddings\n",
    "\n",
    "Now you are ready to train your own word embeddings! In particular, you need to train embeddings specially for our task of duplicates detection. Unfortunately, StarSpace cannot be run on Windows and we recommend to use provided\n",
    "[docker container](https://github.com/hse-aml/natural-language-processing/blob/master/Docker-tutorial.md) or other alternatives. Don't delete results of this task because you will need it in the final project.\n",
    "\n",
    "### How it works and what's the main difference with word2vec?\n",
    "The main point in this section is that StarSpace can be trained specifically for some tasks. In contrast to word2vec model, which tries to train similar embeddings for words in similar contexts, StarSpace uses embeddings for the whole sentence (just as a sum of embeddings of words and phrases). Despite the fact that in both cases we get word embeddings as a result of the training, StarSpace embeddings are trained using some supervised data, e.g. a set of similar sentence pairs, and thus they can better suit the task.\n",
    "\n",
    "In our case, StarSpace should use two types of sentence pairs for training: \"positive\" and \"negative\". \"Positive\" examples are extracted from the train sample (duplicates, high similarity) and the \"negative\" examples are generated randomly (low similarity assumed). \n",
    "\n",
    "### How to choose the best params for the model?\n",
    "Normally, you would start with some default choice and then run extensive experiments to compare different strategies. However, we have some recommendations ready for you to save your time:\n",
    "- Be careful with choosing the suitable training mode. In this task we want to explore texts similarity which corresponds to *trainMode = 3*.\n",
    "- Use adagrad optimization (parameter *adagrad = true*).\n",
    "- Set the length of phrase equal to 1 (parameter *ngrams*), because we need embeddings only for words.\n",
    "- Don't use a large number of *epochs* (we think that 5 should be enough).\n",
    "- Try dimension *dim* equal to 100.\n",
    "- To compare embeddings usually *cosine* *similarity* is used.\n",
    "- Set *minCount* greater than 1 (for example, 2) if you don't want to get embeddings for extremely rare words.\n",
    "- Parameter *verbose = true* could show you the progress of the training process.\n",
    "- Set parameter *fileFormat* equals *labelDoc*.\n",
    "- Parameter *negSearchLimit* is responsible for a number of negative examples which is used during the training. We think that 10 will be enought for this task.\n",
    "- To increase a speed of training we recommend to set *learning rate* to 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train StarSpace embeddings for unigrams on the train dataset. You don't need to change the format of the input data. Just don't forget to use prepared version of the training data. \n",
    "\n",
    "If you follow the instruction, the training process will take about 1 hour. The size of the embeddings' dictionary should be approximately 100 000 (number of lines in the result file). If you got significantly more than this number, try to check all the instructions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: \n",
      "lr: 0.05\n",
      "dim: 100\n",
      "epoch: 5\n",
      "maxTrainTime: 8640000\n",
      "validationPatience: 10\n",
      "saveEveryEpoch: 0\n",
      "loss: hinge\n",
      "margin: 0.05\n",
      "similarity: cosine\n",
      "maxNegSamples: 10\n",
      "negSearchLimit: 10\n",
      "batchSize: 5\n",
      "thread: 10\n",
      "minCount: 2\n",
      "minCountLabel: 1\n",
      "label: __label__\n",
      "label: __label__\n",
      "ngrams: 1\n",
      "bucket: 2000000\n",
      "adagrad: 1\n",
      "trainMode: 1\n",
      "fileFormat: labelDoc\n",
      "normalizeText: 0\n",
      "dropoutLHS: 0\n",
      "dropoutRHS: 0\n",
      "useWeight: 0\n",
      "weightSep: :\n",
      "Start to initialize starspace model.\n",
      "Build dict from input file : /home/karen/Downloads/data/stackoverflow_qa/train_prepared.tsv\n",
      "Read 12M words\n",
      "Number of words in dictionary:  95058\n",
      "Number of labels in dictionary: 0\n",
      "Loading data from file : /home/karen/Downloads/data/stackoverflow_qa/train_prepared.tsv\n",
      "Total number of examples loaded : 999740\n",
      "Initialized model weights. Model size :\n",
      "matrix : 95058 100\n",
      "Training epoch 0: 0.05 0.01\n",
      "Epoch: 100.0%  lr: 0.040210  loss: 0.041422  eta: 0h2m  tot: 0h0m43s  (20.0%)3%  lr: 0.049039  loss: 0.096336  eta: 0h3m  tot: 0h0m4s  (2.3%)15.8%  lr: 0.048589  loss: 0.084779  eta: 0h3m  tot: 0h0m7s  (3.2%)%  lr: 0.048148  loss: 0.078611  eta: 0h3m  tot: 0h0m8s  (3.8%)0h3m  tot: 0h0m8s  (3.9%)20.3%  lr: 0.048038  loss: 0.076456  eta: 0h3m  tot: 0h0m9s  (4.1%)21.2%  lr: 0.047978  loss: 0.075057  eta: 0h3m  tot: 0h0m9s  (4.2%)29.7%  lr: 0.047227  loss: 0.066032  eta: 0h3m  tot: 0h0m13s  (5.9%)30.2%  lr: 0.047207  loss: 0.065489  eta: 0h3m  tot: 0h0m13s  (6.0%)30.6%  lr: 0.047167  loss: 0.065374  eta: 0h3m  tot: 0h0m13s  (6.1%)31.0%  lr: 0.047157  loss: 0.065046  eta: 0h3m  tot: 0h0m14s  (6.2%)31.1%  lr: 0.047157  loss: 0.064990  eta: 0h3m  tot: 0h0m14s  (6.2%)32.5%  lr: 0.047047  loss: 0.063532  eta: 0h3m  tot: 0h0m14s  (6.5%)35.4%  lr: 0.046767  loss: 0.061486  eta: 0h3m  tot: 0h0m16s  (7.1%)37.0%  lr: 0.046617  loss: 0.060233  eta: 0h3m  tot: 0h0m16s  (7.4%)45.1%  lr: 0.045916  loss: 0.055980  eta: 0h3m  tot: 0h0m20s  (9.0%)0.045576  loss: 0.054990  eta: 0h3m  tot: 0h0m21s  (9.5%)0.044995  loss: 0.052471  eta: 0h3m  tot: 0h0m23s  (10.7%)53.7%  lr: 0.044965  loss: 0.052377  eta: 0h3m  tot: 0h0m23s  (10.7%)3m  tot: 0h0m29s  (13.3%)78.0%  lr: 0.042623  loss: 0.045128  eta: 0h3m  tot: 0h0m34s  (15.6%)96.5%  lr: 0.040551  loss: 0.042012  eta: 0h2m  tot: 0h0m42s  (19.3%)96.7%  lr: 0.040531  loss: 0.041988  eta: 0h2m  tot: 0h0m42s  (19.3%)97.9%  lr: 0.040451  loss: 0.041743  eta: 0h2m  tot: 0h0m42s  (19.6%)h0m43s  (19.7%)\n",
      " ---+++                Epoch    0 Train error : 0.04047901 +++--- ☃\n",
      "Training epoch 1: 0.04 0.01\n",
      "Epoch: 100.0%  lr: 0.030070  loss: 0.011480  eta: 0h2m  tot: 0h1m26s  (40.0%)3%  lr: 0.039800  loss: 0.011821  eta: 0h3m  tot: 0h0m46s  (20.5%)6.8%  lr: 0.039459  loss: 0.012539  eta: 0h2m  tot: 0h0m48s  (21.4%)10.4%  lr: 0.039059  loss: 0.012400  eta: 0h2m  tot: 0h0m49s  (22.1%)  lr: 0.038278  loss: 0.012104  eta: 0h2m  tot: 0h0m52s  (23.6%)17.9%  lr: 0.038268  loss: 0.012076  eta: 0h2m  tot: 0h0m52s  (23.6%)24.8%  lr: 0.037618  loss: 0.011498  eta: 0h2m  tot: 0h0m55s  (25.0%)29.7%  lr: 0.037097  loss: 0.011373  eta: 0h2m  tot: 0h0m57s  (25.9%)35.8%  lr: 0.036527  loss: 0.011389  eta: 0h2m  tot: 0h0m59s  (27.2%)41.8%  lr: 0.036046  loss: 0.011270  eta: 0h2m  tot: 0h1m2s  (28.4%)48.0%  lr: 0.035375  loss: 0.011543  eta: 0h2m  tot: 0h1m4s  (29.6%)53.0%  lr: 0.034955  loss: 0.011561  eta: 0h2m  tot: 0h1m6s  (30.6%)63.3%  lr: 0.033924  loss: 0.011462  eta: 0h2m  tot: 0h1m11s  (32.7%)67.3%  lr: 0.033454  loss: 0.011399  eta: 0h2m  tot: 0h1m12s  (33.5%)%  lr: 0.033223  loss: 0.011385  eta: 0h2m  tot: 0h1m13s  (33.7%)70.0%  lr: 0.033143  loss: 0.011376  eta: 0h2m  tot: 0h1m14s  (34.0%)m18s  (36.0%)81.6%  lr: 0.031922  loss: 0.011391  eta: 0h2m  tot: 0h1m18s  (36.3%)83.9%  lr: 0.031622  loss: 0.011402  eta: 0h2m  tot: 0h1m20s  (36.8%)88.0%  lr: 0.031271  loss: 0.011368  eta: 0h2m  tot: 0h1m21s  (37.6%)89.8%  lr: 0.031091  loss: 0.011378  eta: 0h2m  tot: 0h1m22s  (38.0%)2m  tot: 0h1m23s  (38.4%)\n",
      " ---+++                Epoch    1 Train error : 0.01124729 +++--- ☃\n",
      "Training epoch 2: 0.03 0.01\n",
      "Epoch: 100.0%  lr: 0.020280  loss: 0.007802  eta: 0h1m  tot: 0h2m7s  (60.0%).2%  lr: 0.029810  loss: 0.009177  eta: 0h1m  tot: 0h1m28s  (40.4%)3.3%  lr: 0.029720  loss: 0.008712  eta: 0h1m  tot: 0h1m29s  (40.7%)13.9%  lr: 0.028669  loss: 0.008070  eta: 0h1m  tot: 0h1m32s  (42.8%)16.6%  lr: 0.028378  loss: 0.008017  eta: 0h1m  tot: 0h1m34s  (43.3%)22.1%  lr: 0.027898  loss: 0.007813  eta: 0h1m  tot: 0h1m36s  (44.4%)32.2%  lr: 0.027037  loss: 0.007738  eta: 0h1m  tot: 0h1m40s  (46.4%)38.5%  lr: 0.026507  loss: 0.007538  eta: 0h1m  tot: 0h1m42s  (47.7%)38.9%  lr: 0.026467  loss: 0.007546  eta: 0h1m  tot: 0h1m42s  (47.8%)50.5%  lr: 0.025335  loss: 0.007543  eta: 0h1m  tot: 0h1m47s  (50.1%)53.6%  lr: 0.025005  loss: 0.007570  eta: 0h1m  tot: 0h1m48s  (50.7%)54.4%  lr: 0.024885  loss: 0.007557  eta: 0h1m  tot: 0h1m49s  (50.9%)  tot: 0h1m49s  (50.9%)59.5%  lr: 0.024314  loss: 0.007618  eta: 0h1m  tot: 0h1m51s  (51.9%)0.023934  loss: 0.007675  eta: 0h1m  tot: 0h1m53s  (53.1%)67.7%  lr: 0.023724  loss: 0.007657  eta: 0h1m  tot: 0h1m54s  (53.5%)70.8%  lr: 0.023444  loss: 0.007661  eta: 0h1m  tot: 0h1m56s  (54.2%)74.1%  lr: 0.022903  loss: 0.007632  eta: 0h1m  tot: 0h1m57s  (54.8%)74.4%  lr: 0.022863  loss: 0.007629  eta: 0h1m  tot: 0h1m57s  (54.9%)s  (54.9%)74.7%  lr: 0.022843  loss: 0.007627  eta: 0h1m  tot: 0h1m58s  (54.9%)76.2%  lr: 0.022693  loss: 0.007663  eta: 0h1m  tot: 0h1m58s  (55.2%)80.0%  lr: 0.022393  loss: 0.007707  eta: 0h1m  tot: 0h2m0s  (56.0%)0h1m  tot: 0h2m3s  (57.6%)87.9%  lr: 0.021392  loss: 0.007779  eta: 0h1m  tot: 0h2m3s  (57.6%)88.0%  lr: 0.021372  loss: 0.007775  eta: 0h1m  tot: 0h2m3s  (57.6%)\n",
      " ---+++                Epoch    2 Train error : 0.00775036 +++--- ☃\n",
      "Training epoch 3: 0.02 0.01\n",
      "Epoch: 100.0%  lr: 0.010230  loss: 0.006204  eta: <1min   tot: 0h2m49s  (80.0%)4%  lr: 0.019500  loss: 0.006825  eta: 0h1m  tot: 0h2m12s  (61.1%)8.7%  lr: 0.019139  loss: 0.006101  eta: 0h1m  tot: 0h2m13s  (61.7%)%  lr: 0.018268  loss: 0.005908  eta: 0h1m  tot: 0h2m16s  (63.4%)16.9%  lr: 0.018258  loss: 0.005908  eta: 0h1m  tot: 0h2m16s  (63.4%)17.1%  lr: 0.018228  loss: 0.005926  eta: 0h1m  tot: 0h2m17s  (63.4%)17.8%  lr: 0.018148  loss: 0.005924  eta: 0h1m  tot: 0h2m17s  (63.6%)18.7%  lr: 0.018118  loss: 0.006032  eta: 0h1m  tot: 0h2m17s  (63.7%)19.8%  lr: 0.018048  loss: 0.006102  eta: 0h1m  tot: 0h2m18s  (64.0%)23.9%  lr: 0.017838  loss: 0.006040  eta: 0h1m  tot: 0h2m19s  (64.8%)25.2%  lr: 0.017668  loss: 0.006013  eta: 0h1m  tot: 0h2m19s  (65.0%)35.9%  lr: 0.016607  loss: 0.006065  eta: 0h1m  tot: 0h2m23s  (67.2%)40.3%  lr: 0.016276  loss: 0.006152  eta: 0h1m  tot: 0h2m25s  (68.1%)40.5%  lr: 0.016226  loss: 0.006157  eta: 0h1m  tot: 0h2m25s  (68.1%)46.0%  lr: 0.015776  loss: 0.006205  eta: <1min   tot: 0h2m27s  (69.2%)46.1%  lr: 0.015766  loss: 0.006197  eta: <1min   tot: 0h2m27s  (69.2%)h2m32s  (71.5%)57.8%  lr: 0.014815  loss: 0.006151  eta: <1min   tot: 0h2m32s  (71.6%)60.0%  lr: 0.014495  loss: 0.006138  eta: <1min   tot: 0h2m33s  (72.0%)61.9%  lr: 0.014184  loss: 0.006130  eta: <1min   tot: 0h2m34s  (72.4%)63.1%  lr: 0.013974  loss: 0.006124  eta: <1min   tot: 0h2m35s  (72.6%)64.5%  lr: 0.013834  loss: 0.006131  eta: <1min   tot: 0h2m35s  (72.9%)64.8%  lr: 0.013794  loss: 0.006137  eta: <1min   tot: 0h2m35s  (73.0%)64.9%  lr: 0.013794  loss: 0.006135  eta: <1min   tot: 0h2m35s  (73.0%)68.1%  lr: 0.013504  loss: 0.006131  eta: <1min   tot: 0h2m37s  (73.6%)68.6%  lr: 0.013484  loss: 0.006140  eta: <1min   tot: 0h2m37s  (73.7%)68.7%  lr: 0.013454  loss: 0.006137  eta: <1min   tot: 0h2m37s  (73.7%)69.9%  lr: 0.013353  loss: 0.006120  eta: <1min   tot: 0h2m38s  (74.0%) (74.0%)70.8%  lr: 0.013283  loss: 0.006137  eta: <1min   tot: 0h2m38s  (74.2%)70.8%  lr: 0.013273  loss: 0.006139  eta: <1min   tot: 0h2m38s  (74.2%)72.5%  lr: 0.013103  loss: 0.006133  eta: <1min   tot: 0h2m39s  (74.5%)72.6%  lr: 0.013073  loss: 0.006130  eta: <1min   tot: 0h2m39s  (74.5%)72.6%  lr: 0.013063  loss: 0.006131  eta: <1min   tot: 0h2m39s  (74.5%)75.5%  lr: 0.012723  loss: 0.006138  eta: <1min   tot: 0h2m40s  (75.1%)75.7%  lr: 0.012713  loss: 0.006141  eta: <1min   tot: 0h2m40s  (75.1%)75.8%  lr: 0.012693  loss: 0.006136  eta: <1min   tot: 0h2m40s  (75.2%)88.2%  lr: 0.011291  loss: 0.006168  eta: <1min   tot: 0h2m45s  (77.6%)\n",
      " ---+++                Epoch    3 Train error : 0.00627947 +++--- ☃\n",
      "Training epoch 4: 0.01 0.01\n",
      "Epoch: 100.0%  lr: 0.000130  loss: 0.005666  eta: <1min   tot: 0h3m30s  (100.0%).5%  lr: 0.008589  loss: 0.005833  eta: <1min   tot: 0h2m56s  (82.7%)14.0%  lr: 0.008509  loss: 0.005813  eta: <1min   tot: 0h2m56s  (82.8%)14.1%  lr: 0.008479  loss: 0.005796  eta: <1min   tot: 0h2m56s  (82.8%)15.2%  lr: 0.008338  loss: 0.005833  eta: <1min   tot: 0h2m57s  (83.0%)%  lr: 0.006316  loss: 0.005914  eta: <1min   tot: 0h3m5s  (87.7%)41.0%  lr: 0.006096  loss: 0.005817  eta: <1min   tot: 0h3m6s  (88.2%)46.5%  lr: 0.005526  loss: 0.005758  eta: <1min   tot: 0h3m8s  (89.3%)52.9%  lr: 0.004745  loss: 0.005835  eta: <1min   tot: 0h3m11s  (90.6%)53.0%  lr: 0.004725  loss: 0.005835  eta: <1min   tot: 0h3m11s  (90.6%)60.5%  lr: 0.003944  loss: 0.005813  eta: <1min   tot: 0h3m14s  (92.1%)68.1%  lr: 0.003223  loss: 0.005806  eta: <1min   tot: 0h3m17s  (93.6%)78.0%  lr: 0.002222  loss: 0.005713  eta: <1min   tot: 0h3m21s  (95.6%)0.005717  eta: <1min   tot: 0h3m22s  (95.8%)80.1%  lr: 0.002062  loss: 0.005700  eta: <1min   tot: 0h3m22s  (96.0%)%  lr: 0.001822  loss: 0.005669  eta: <1min   tot: 0h3m23s  (96.5%)82.7%  lr: 0.001782  loss: 0.005662  eta: <1min   tot: 0h3m23s  (96.5%)84.7%  lr: 0.001572  loss: 0.005664  eta: <1min   tot: 0h3m24s  (96.9%)84.9%  lr: 0.001552  loss: 0.005665  eta: <1min   tot: 0h3m24s  (97.0%)86.1%  lr: 0.001401  loss: 0.005676  eta: <1min   tot: 0h3m25s  (97.2%)87.7%  lr: 0.001191  loss: 0.005667  eta: <1min   tot: 0h3m26s  (97.5%)90.5%  lr: 0.000981  loss: 0.005647  eta: <1min   tot: 0h3m27s  (98.1%)90.6%  lr: 0.000971  loss: 0.005647  eta: <1min   tot: 0h3m27s  (98.1%)0.005651  eta: <1min   tot: 0h3m28s  (98.6%)\n",
      " ---+++                Epoch    4 Train error : 0.00552513 +++--- ☃\n",
      "Saving model to file : starSpaceModel\n",
      "Saving model in tsv format : starSpaceModel.tsv\n"
     ]
    }
   ],
   "source": [
    "!Starspace/starspace train -trainFile /home/karen/Downloads/data/stackoverflow_qa/train_prepared.tsv -trainMode 1 -adagrad  true -ngrams  1 -dim 100 -minCount  2 -verbose true -fileFormat labelDoc -negSearchLimit 10 -lr 0.05 -model starSpaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And now we can compare the new embeddings with the previous ones. You can find trained word vectors in the file *[model_file_name].tsv*. Upload the embeddings from StarSpace into a dict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['0.029723', '0.00126978', '0.0109264', '-0.00850125', '-0.0038752', '-0.0136108', '0.0143892', '0.021096', '0.0164289', '0.0155355', '-0.00481273', '0.00164163', '-0.0135173', '-0.022791', '-0.00448459', '-0.00856387', '0.0123847', '-0.0166097', '-0.0145041', '-0.00913096', '-0.00511055', '-0.00183105', '0.00316092', '0.00750908', '0.0140855', '-0.00503389', '-0.0233016', '-0.0110876', '-0.000840746', '-0.00260444', '0.00594024', '-0.00771097', '-0.0171782', '0.00662687', '-0.0187548', '-0.000361999', '0.001136', '0.0155511', '-0.00695704', '0.0100371', '-0.0239684', '-0.0160961', '0.0239641', '0.00748706', '-0.0272093', '-0.0109743', '-0.00453283', '0.0126349', '-0.0172669', '-0.0192649', '-0.0284429', '0.00128225', '-0.00354485', '0.0227757', '-0.0119172', '-0.0434495', '-0.00242183', '0.0132759', '0.00843015', '0.010946', '0.00359454', '-0.0123595', '-0.0323981', '-0.00386617', '0.0219424', '0.00188741', '-0.00872709', '-0.00303016', '0.00249568', '0.00170681', '-0.0189029', '-0.00333945', '0.00156616', '-0.00864972', '0.0237695', '-0.0192529', '0.0186781', '-0.00780661', '0.00895939', '0.0363481', '-0.0168534', '0.0199988', '0.00831792', '0.0130084', '-0.00221791', '-0.00218479', '-0.0143731', '-0.019538', '-0.000493535', '0.00952925', '-0.0180687', '-0.0192704', '-0.00861405', '-0.0016274', '-0.0132334', '-0.0195235', '-0.00542936', '0.0142023', '-0.0216396', '-0.013571']\n",
      "android ['0.0435417', '-0.0220413', '0.00170758', '0.048823', '-0.0380503', '0.0392927', '-0.0816547', '-0.0684202', '-0.000857129', '0.0238051', '-0.0658644', '0.0966767', '0.031037', '0.0551987', '-0.0366344', '-0.0310792', '-0.0356214', '0.0587808', '0.0391142', '0.0417479', '0.0320238', '-0.0353602', '-0.0561454', '-0.0191956', '-0.00651602', '0.0902869', '0.0198727', '0.0247662', '0.029925', '-0.00559013', '0.00302509', '-0.00750417', '-0.0279356', '-0.0142216', '-0.0132598', '-0.0935611', '-0.069565', '-0.0284194', '-0.0357235', '-0.0292767', '-0.0283342', '-0.00776604', '0.0740529', '-0.0372215', '0.0302156', '0.127541', '-0.0802181', '-0.045642', '0.0368337', '0.0108535', '0.0321513', '0.0385698', '-0.0167024', '0.00235224', '-0.020228', '0.0419971', '0.0257452', '0.019614', '0.0609394', '-0.0508168', '-0.0165766', '-0.0346119', '-0.045393', '-0.0644465', '-0.000469867', '0.0470857', '0.0449405', '0.00704461', '-0.028489', '-0.0396068', '-0.0560744', '-0.0207005', '0.0419688', '-0.0643158', '0.0111606', '-0.0429499', '0.0313257', '0.158323', '-0.0326176', '-0.0107663', '-0.0459206', '-0.0282815', '0.0332167', '-0.0170824', '0.00903165', '0.0514633', '-0.0281648', '0.0153899', '-0.0479591', '0.00225214', '-0.0556554', '-0.0358147', '0.0500505', '0.0275733', '-0.0851097', '0.0205345', '-0.00793158', '0.0369989', '0.0162405', '-0.0237383']\n",
      "file ['0.0160304', '0.0277767', '0.0493223', '-0.0905856', '-0.0326107', '-0.0436962', '-0.0159054', '-0.0277565', '-0.00885271', '-0.0122965', '-0.0225354', '0.00329215', '0.018838', '-0.0268556', '0.0252573', '-0.000468992', '0.0103021', '0.0163106', '-0.0150567', '-0.0666035', '0.0534003', '-0.0531005', '-0.00858594', '0.0364725', '0.004637', '-0.062989', '0.0103234', '-0.0343916', '-0.0437138', '-0.0200621', '-0.00112834', '-0.030855', '-0.00643466', '-0.0526987', '0.0108271', '-0.0497089', '-0.0304861', '-0.00873746', '-0.0468633', '-0.00607005', '0.019863', '0.0173737', '0.0337132', '0.0326444', '0.0378808', '-0.0227903', '-0.00739579', '0.0326232', '0.0136639', '0.0206415', '-0.0399124', '-0.00457053', '0.0189615', '-0.0581371', '0.0180678', '0.0574025', '0.00481064', '-0.00401029', '0.02804', '-0.0202684', '0.0238493', '-0.0109024', '-0.00232526', '0.0177934', '-0.0135791', '-0.020684', '0.0599593', '0.015897', '-0.00432895', '0.0437439', '-0.0344709', '0.00849715', '-0.0880545', '0.00954357', '-0.0194695', '-0.0201784', '0.0282918', '-0.0276579', '0.0620186', '-0.0111266', '0.033405', '0.0169657', '0.0403869', '0.017715', '-0.00890745', '0.0116668', '0.0241104', '0.0202112', '-0.00598655', '0.0619874', '0.0331208', '-0.0261369', '0.0904504', '0.100958', '0.0395862', '0.0188665', '-0.024903', '0.0130408', '-0.0805284', '-0.0270639']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for vec in open('starSpaceModel.tsv'):\n",
    "    if i<3:\n",
    "        print(vec.split('\\t')[0], list(map(lambda x: x.replace('\\n', ''), vec.split('\\t')[1:])))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [vec.split('\\t')[0] for vec in open('starSpaceModel.tsv')]\n",
    "word_vec = [list(map(lambda x: float(x.replace('\\n', '')), vec.split('\\t')[1:])) for vec in open('starSpaceModel.tsv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['using', 'android', 'file'],\n",
       " [[0.029723,\n",
       "   0.00126978,\n",
       "   0.0109264,\n",
       "   -0.00850125,\n",
       "   -0.0038752,\n",
       "   -0.0136108,\n",
       "   0.0143892,\n",
       "   0.021096,\n",
       "   0.0164289,\n",
       "   0.0155355,\n",
       "   -0.00481273,\n",
       "   0.00164163,\n",
       "   -0.0135173,\n",
       "   -0.022791,\n",
       "   -0.00448459,\n",
       "   -0.00856387,\n",
       "   0.0123847,\n",
       "   -0.0166097,\n",
       "   -0.0145041,\n",
       "   -0.00913096,\n",
       "   -0.00511055,\n",
       "   -0.00183105,\n",
       "   0.00316092,\n",
       "   0.00750908,\n",
       "   0.0140855,\n",
       "   -0.00503389,\n",
       "   -0.0233016,\n",
       "   -0.0110876,\n",
       "   -0.000840746,\n",
       "   -0.00260444,\n",
       "   0.00594024,\n",
       "   -0.00771097,\n",
       "   -0.0171782,\n",
       "   0.00662687,\n",
       "   -0.0187548,\n",
       "   -0.000361999,\n",
       "   0.001136,\n",
       "   0.0155511,\n",
       "   -0.00695704,\n",
       "   0.0100371,\n",
       "   -0.0239684,\n",
       "   -0.0160961,\n",
       "   0.0239641,\n",
       "   0.00748706,\n",
       "   -0.0272093,\n",
       "   -0.0109743,\n",
       "   -0.00453283,\n",
       "   0.0126349,\n",
       "   -0.0172669,\n",
       "   -0.0192649,\n",
       "   -0.0284429,\n",
       "   0.00128225,\n",
       "   -0.00354485,\n",
       "   0.0227757,\n",
       "   -0.0119172,\n",
       "   -0.0434495,\n",
       "   -0.00242183,\n",
       "   0.0132759,\n",
       "   0.00843015,\n",
       "   0.010946,\n",
       "   0.00359454,\n",
       "   -0.0123595,\n",
       "   -0.0323981,\n",
       "   -0.00386617,\n",
       "   0.0219424,\n",
       "   0.00188741,\n",
       "   -0.00872709,\n",
       "   -0.00303016,\n",
       "   0.00249568,\n",
       "   0.00170681,\n",
       "   -0.0189029,\n",
       "   -0.00333945,\n",
       "   0.00156616,\n",
       "   -0.00864972,\n",
       "   0.0237695,\n",
       "   -0.0192529,\n",
       "   0.0186781,\n",
       "   -0.00780661,\n",
       "   0.00895939,\n",
       "   0.0363481,\n",
       "   -0.0168534,\n",
       "   0.0199988,\n",
       "   0.00831792,\n",
       "   0.0130084,\n",
       "   -0.00221791,\n",
       "   -0.00218479,\n",
       "   -0.0143731,\n",
       "   -0.019538,\n",
       "   -0.000493535,\n",
       "   0.00952925,\n",
       "   -0.0180687,\n",
       "   -0.0192704,\n",
       "   -0.00861405,\n",
       "   -0.0016274,\n",
       "   -0.0132334,\n",
       "   -0.0195235,\n",
       "   -0.00542936,\n",
       "   0.0142023,\n",
       "   -0.0216396,\n",
       "   -0.013571],\n",
       "  [0.0435417,\n",
       "   -0.0220413,\n",
       "   0.00170758,\n",
       "   0.048823,\n",
       "   -0.0380503,\n",
       "   0.0392927,\n",
       "   -0.0816547,\n",
       "   -0.0684202,\n",
       "   -0.000857129,\n",
       "   0.0238051,\n",
       "   -0.0658644,\n",
       "   0.0966767,\n",
       "   0.031037,\n",
       "   0.0551987,\n",
       "   -0.0366344,\n",
       "   -0.0310792,\n",
       "   -0.0356214,\n",
       "   0.0587808,\n",
       "   0.0391142,\n",
       "   0.0417479,\n",
       "   0.0320238,\n",
       "   -0.0353602,\n",
       "   -0.0561454,\n",
       "   -0.0191956,\n",
       "   -0.00651602,\n",
       "   0.0902869,\n",
       "   0.0198727,\n",
       "   0.0247662,\n",
       "   0.029925,\n",
       "   -0.00559013,\n",
       "   0.00302509,\n",
       "   -0.00750417,\n",
       "   -0.0279356,\n",
       "   -0.0142216,\n",
       "   -0.0132598,\n",
       "   -0.0935611,\n",
       "   -0.069565,\n",
       "   -0.0284194,\n",
       "   -0.0357235,\n",
       "   -0.0292767,\n",
       "   -0.0283342,\n",
       "   -0.00776604,\n",
       "   0.0740529,\n",
       "   -0.0372215,\n",
       "   0.0302156,\n",
       "   0.127541,\n",
       "   -0.0802181,\n",
       "   -0.045642,\n",
       "   0.0368337,\n",
       "   0.0108535,\n",
       "   0.0321513,\n",
       "   0.0385698,\n",
       "   -0.0167024,\n",
       "   0.00235224,\n",
       "   -0.020228,\n",
       "   0.0419971,\n",
       "   0.0257452,\n",
       "   0.019614,\n",
       "   0.0609394,\n",
       "   -0.0508168,\n",
       "   -0.0165766,\n",
       "   -0.0346119,\n",
       "   -0.045393,\n",
       "   -0.0644465,\n",
       "   -0.000469867,\n",
       "   0.0470857,\n",
       "   0.0449405,\n",
       "   0.00704461,\n",
       "   -0.028489,\n",
       "   -0.0396068,\n",
       "   -0.0560744,\n",
       "   -0.0207005,\n",
       "   0.0419688,\n",
       "   -0.0643158,\n",
       "   0.0111606,\n",
       "   -0.0429499,\n",
       "   0.0313257,\n",
       "   0.158323,\n",
       "   -0.0326176,\n",
       "   -0.0107663,\n",
       "   -0.0459206,\n",
       "   -0.0282815,\n",
       "   0.0332167,\n",
       "   -0.0170824,\n",
       "   0.00903165,\n",
       "   0.0514633,\n",
       "   -0.0281648,\n",
       "   0.0153899,\n",
       "   -0.0479591,\n",
       "   0.00225214,\n",
       "   -0.0556554,\n",
       "   -0.0358147,\n",
       "   0.0500505,\n",
       "   0.0275733,\n",
       "   -0.0851097,\n",
       "   0.0205345,\n",
       "   -0.00793158,\n",
       "   0.0369989,\n",
       "   0.0162405,\n",
       "   -0.0237383],\n",
       "  [0.0160304,\n",
       "   0.0277767,\n",
       "   0.0493223,\n",
       "   -0.0905856,\n",
       "   -0.0326107,\n",
       "   -0.0436962,\n",
       "   -0.0159054,\n",
       "   -0.0277565,\n",
       "   -0.00885271,\n",
       "   -0.0122965,\n",
       "   -0.0225354,\n",
       "   0.00329215,\n",
       "   0.018838,\n",
       "   -0.0268556,\n",
       "   0.0252573,\n",
       "   -0.000468992,\n",
       "   0.0103021,\n",
       "   0.0163106,\n",
       "   -0.0150567,\n",
       "   -0.0666035,\n",
       "   0.0534003,\n",
       "   -0.0531005,\n",
       "   -0.00858594,\n",
       "   0.0364725,\n",
       "   0.004637,\n",
       "   -0.062989,\n",
       "   0.0103234,\n",
       "   -0.0343916,\n",
       "   -0.0437138,\n",
       "   -0.0200621,\n",
       "   -0.00112834,\n",
       "   -0.030855,\n",
       "   -0.00643466,\n",
       "   -0.0526987,\n",
       "   0.0108271,\n",
       "   -0.0497089,\n",
       "   -0.0304861,\n",
       "   -0.00873746,\n",
       "   -0.0468633,\n",
       "   -0.00607005,\n",
       "   0.019863,\n",
       "   0.0173737,\n",
       "   0.0337132,\n",
       "   0.0326444,\n",
       "   0.0378808,\n",
       "   -0.0227903,\n",
       "   -0.00739579,\n",
       "   0.0326232,\n",
       "   0.0136639,\n",
       "   0.0206415,\n",
       "   -0.0399124,\n",
       "   -0.00457053,\n",
       "   0.0189615,\n",
       "   -0.0581371,\n",
       "   0.0180678,\n",
       "   0.0574025,\n",
       "   0.00481064,\n",
       "   -0.00401029,\n",
       "   0.02804,\n",
       "   -0.0202684,\n",
       "   0.0238493,\n",
       "   -0.0109024,\n",
       "   -0.00232526,\n",
       "   0.0177934,\n",
       "   -0.0135791,\n",
       "   -0.020684,\n",
       "   0.0599593,\n",
       "   0.015897,\n",
       "   -0.00432895,\n",
       "   0.0437439,\n",
       "   -0.0344709,\n",
       "   0.00849715,\n",
       "   -0.0880545,\n",
       "   0.00954357,\n",
       "   -0.0194695,\n",
       "   -0.0201784,\n",
       "   0.0282918,\n",
       "   -0.0276579,\n",
       "   0.0620186,\n",
       "   -0.0111266,\n",
       "   0.033405,\n",
       "   0.0169657,\n",
       "   0.0403869,\n",
       "   0.017715,\n",
       "   -0.00890745,\n",
       "   0.0116668,\n",
       "   0.0241104,\n",
       "   0.0202112,\n",
       "   -0.00598655,\n",
       "   0.0619874,\n",
       "   0.0331208,\n",
       "   -0.0261369,\n",
       "   0.0904504,\n",
       "   0.100958,\n",
       "   0.0395862,\n",
       "   0.0188665,\n",
       "   -0.024903,\n",
       "   0.0130408,\n",
       "   -0.0805284,\n",
       "   -0.0270639]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:3], word_vec[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "starspace_embeddings = {w:np.array(v) for w, v in zip(words,word_vec)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starspace_embeddings[\"words\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using [ 0.029723    0.00126978  0.0109264  -0.00850125 -0.0038752  -0.0136108\n",
      "  0.0143892   0.021096    0.0164289   0.0155355  -0.00481273  0.00164163\n",
      " -0.0135173  -0.022791   -0.00448459 -0.00856387  0.0123847  -0.0166097\n",
      " -0.0145041  -0.00913096 -0.00511055 -0.00183105  0.00316092  0.00750908\n",
      "  0.0140855  -0.00503389 -0.0233016  -0.0110876  -0.00084075 -0.00260444\n",
      "  0.00594024 -0.00771097 -0.0171782   0.00662687 -0.0187548  -0.000362\n",
      "  0.001136    0.0155511  -0.00695704  0.0100371  -0.0239684  -0.0160961\n",
      "  0.0239641   0.00748706 -0.0272093  -0.0109743  -0.00453283  0.0126349\n",
      " -0.0172669  -0.0192649  -0.0284429   0.00128225 -0.00354485  0.0227757\n",
      " -0.0119172  -0.0434495  -0.00242183  0.0132759   0.00843015  0.010946\n",
      "  0.00359454 -0.0123595  -0.0323981  -0.00386617  0.0219424   0.00188741\n",
      " -0.00872709 -0.00303016  0.00249568  0.00170681 -0.0189029  -0.00333945\n",
      "  0.00156616 -0.00864972  0.0237695  -0.0192529   0.0186781  -0.00780661\n",
      "  0.00895939  0.0363481  -0.0168534   0.0199988   0.00831792  0.0130084\n",
      " -0.00221791 -0.00218479 -0.0143731  -0.019538   -0.00049354  0.00952925\n",
      " -0.0180687  -0.0192704  -0.00861405 -0.0016274  -0.0132334  -0.0195235\n",
      " -0.00542936  0.0142023  -0.0216396  -0.013571  ]\n",
      "android [ 0.0435417  -0.0220413   0.00170758  0.048823   -0.0380503   0.0392927\n",
      " -0.0816547  -0.0684202  -0.00085713  0.0238051  -0.0658644   0.0966767\n",
      "  0.031037    0.0551987  -0.0366344  -0.0310792  -0.0356214   0.0587808\n",
      "  0.0391142   0.0417479   0.0320238  -0.0353602  -0.0561454  -0.0191956\n",
      " -0.00651602  0.0902869   0.0198727   0.0247662   0.029925   -0.00559013\n",
      "  0.00302509 -0.00750417 -0.0279356  -0.0142216  -0.0132598  -0.0935611\n",
      " -0.069565   -0.0284194  -0.0357235  -0.0292767  -0.0283342  -0.00776604\n",
      "  0.0740529  -0.0372215   0.0302156   0.127541   -0.0802181  -0.045642\n",
      "  0.0368337   0.0108535   0.0321513   0.0385698  -0.0167024   0.00235224\n",
      " -0.020228    0.0419971   0.0257452   0.019614    0.0609394  -0.0508168\n",
      " -0.0165766  -0.0346119  -0.045393   -0.0644465  -0.00046987  0.0470857\n",
      "  0.0449405   0.00704461 -0.028489   -0.0396068  -0.0560744  -0.0207005\n",
      "  0.0419688  -0.0643158   0.0111606  -0.0429499   0.0313257   0.158323\n",
      " -0.0326176  -0.0107663  -0.0459206  -0.0282815   0.0332167  -0.0170824\n",
      "  0.00903165  0.0514633  -0.0281648   0.0153899  -0.0479591   0.00225214\n",
      " -0.0556554  -0.0358147   0.0500505   0.0275733  -0.0851097   0.0205345\n",
      " -0.00793158  0.0369989   0.0162405  -0.0237383 ]\n",
      "file [ 0.0160304   0.0277767   0.0493223  -0.0905856  -0.0326107  -0.0436962\n",
      " -0.0159054  -0.0277565  -0.00885271 -0.0122965  -0.0225354   0.00329215\n",
      "  0.018838   -0.0268556   0.0252573  -0.00046899  0.0103021   0.0163106\n",
      " -0.0150567  -0.0666035   0.0534003  -0.0531005  -0.00858594  0.0364725\n",
      "  0.004637   -0.062989    0.0103234  -0.0343916  -0.0437138  -0.0200621\n",
      " -0.00112834 -0.030855   -0.00643466 -0.0526987   0.0108271  -0.0497089\n",
      " -0.0304861  -0.00873746 -0.0468633  -0.00607005  0.019863    0.0173737\n",
      "  0.0337132   0.0326444   0.0378808  -0.0227903  -0.00739579  0.0326232\n",
      "  0.0136639   0.0206415  -0.0399124  -0.00457053  0.0189615  -0.0581371\n",
      "  0.0180678   0.0574025   0.00481064 -0.00401029  0.02804    -0.0202684\n",
      "  0.0238493  -0.0109024  -0.00232526  0.0177934  -0.0135791  -0.020684\n",
      "  0.0599593   0.015897   -0.00432895  0.0437439  -0.0344709   0.00849715\n",
      " -0.0880545   0.00954357 -0.0194695  -0.0201784   0.0282918  -0.0276579\n",
      "  0.0620186  -0.0111266   0.033405    0.0169657   0.0403869   0.017715\n",
      " -0.00890745  0.0116668   0.0241104   0.0202112  -0.00598655  0.0619874\n",
      "  0.0331208  -0.0261369   0.0904504   0.100958    0.0395862   0.0188665\n",
      " -0.024903    0.0130408  -0.0805284  -0.0270639 ]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for w,v in starspace_embeddings.items():\n",
    "    if i<3:\n",
    "        print(w, v)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1001)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(prepared_validation).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100) (1000, 100)\n"
     ]
    }
   ],
   "source": [
    "ss_prepared_ranking = []\n",
    "for line in prepared_validation:\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, starspace_embeddings, 100)\n",
    "    ss_prepared_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranks [1]\n",
      "DCG@   1: 1.000 | Hits@   1: 1.000\n",
      "ranks [1]\n",
      "DCG@   5: 1.000 | Hits@   5: 1.000\n",
      "ranks [1]\n",
      "DCG@  10: 1.000 | Hits@  10: 1.000\n",
      "ranks [1]\n",
      "DCG@ 100: 1.000 | Hits@ 100: 1.000\n",
      "ranks [1]\n",
      "DCG@ 500: 1.000 | Hits@ 500: 1.000\n",
      "ranks [1]\n",
      "DCG@1000: 1.000 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(ss_prepared_ranking, k), \n",
    "                                               k, hits_count(ss_prepared_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to training for the particular task with the supervised data, you should expect to obtain a higher quality than for the previous approach. In additiion, despite the fact that StarSpace's trained vectors have a smaller dimension than word2vec's, it provides better results in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5 (StarSpaceRanks).** For each question from prepared *test.tsv* submit the ranks of the candidates for trained representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['loops replaced linq statement', 'get flex app load quicker', 'wix installer verify sufficient privileges start system services', 'timer thread pthread c', 'unable use variable defined beforegroup test method', 'finding sequences data frame r', 'calculate possible pairs items two lists', 'display data parse objects recycler view android', 'access windows kernel system calls directly', 'listview items repetition', 'excel functions showing converting excel csv php', 'entity framework query using contains mulitple options', 'spring security filters authentication spring web services', 'force thread update imageview immediately', 'install python3 custom path using chocolatey', 'break lines inside div tag', 'combine html php html shown view source nested correctly', 'animation inside custom alertdialog', 'hadoop cluster wrong permissions upgrade', 'display youtube video html page', 'bootstrap 3 select styling ie', 'paint app jquery mobile object method', 'django admin list page', 'semantic ui grid display full width column computer columns hidden', 'vbscript creating scheduled task', 'bash script start process wait random kill process restart', 'r oracle sql', 'convert widestring string unicode bytes', 'c++ cannot convert parameter 1 const char char', 'get http 500 error use python urllib2open', 'start notification intentservice', 'jpahibernate database restart problem', 'vertical horizontal data arrangement page crystal reports', 'haskell techniques mixed part structure part unmodified text parsing rewriting', 'node js post request body undefined', 'didchangeobject called nsfetchedresultscontroller', 'unique 4 digit random number c#', 'tcp ip possible read tcp udp data program sending remotely', 'hibernate postgres target lists 1664 entries', 'importing chartjs aurelia causes page errors bunldling', 'edited uiimagepickercontrollerh mistake getting errors project', 'returning expression ghc monad', 'wcf error cannot obtain metadata', 'ajax polling symfony process component', 'extract data cell excel', 'treetagger r', 'cannot use ortools google', 'get javascript prompt value protractor', 'c# aspnet 35 deserialize json get object string', 'avoid net native bugs', 'run play framework port9001 windows cmd play console', 'hook sharepoint 2007 feature application_start site', 'pulling geojson data leaflet ajax call', 'jekyll button url working', 'iterative bst insertion c++', 'suitable way scale rest api window azure handle thousands requests', 'b character stored string python', 'switching bits nibble int', 'building clusters based partnership', 'create form select making value option text db array', 'es6 generators example yield expression first next', 'ripple drawable effect appearing differently listview recyclerview', 'matplotlib objectoriented code display inline notebook', 'disable enableglobalmethodsecurity annotation', 'upload file codeigniter app dropbox', 'uppercasing variable makefile', 'config_hid_multitouch parameter values android kernel', 'stuck fixing query mistakes two commands wrote', 'create array mysql query php', 'meteor possible flush per row table', 'foundation 4unable overwrite regular expression validate password', 'make 3d model onclick events display website', 'validate checkbox aspnet c#', 'dav svn config server hosting multiple domains', 'npm error specified procedure could found', 'matlab error using assignin attempt add c static workspace', 'view fit canvas canvas scale', 'query working worked hours', 'possible generate xml sql dont know number levels', 'create app aweber', 'multidimensional arrays using range simultaneously set start stop step', 'xamarin mac 210 compatible exif library', 'change string int', 'implement serverside rate limiting perl web service', 'change add chart data series pythonpptx', 'solving profit algorithm', 'way get list users custom audience', 'jms transaction', 'precision recall multiclassmultilabel classification', 'mavenpluginapi comthoughtworksqdoxparserparseexception', 'visual diagram format gui event mapping', 'sql server query get details table single column multiple rows', 'oracle recursive query using start connected', 'pass json data nunjucks template', 'unable replace arabic characters apache poi ms word file', 'android jobscheduler jobservice network constraint start even device network connection', 'reflexive manytomany relationship cakephp', 'show timer ios lock screen', 'error windows phone emulator', 'produce sum column sql']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task StarSpaceRanks is: 80\t57\t78\t12\t3\t81\t37\t63\t61\t47\t49\t10\t58\t19\t85\t68\t17\t87\t55\t98\t77\t93\t23\t75\t90\t62\t73\t94\t29\t1\t65\t27\t91\t59\t...\n"
     ]
    }
   ],
   "source": [
    "starspace_ranks_results = []\n",
    "prepared_test_data = '/home/karen/Downloads/data/stackoverflow_qa/test_prepared.tsv'\n",
    "for line in open(prepared_test_data):\n",
    "    q, *ex = line.strip().split('\\t')\n",
    "    ranks = rank_candidates(q, ex, starspace_embeddings, dim=100)\n",
    "    ranked_candidates = [r[0] for r in ranks]\n",
    "    starspace_ranks_results.append([ranked_candidates.index(i) + 1 for i in range(len(ranked_candidates))])\n",
    "    \n",
    "grader.submit_tag('StarSpaceRanks', matrix_to_string(starspace_ranks_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, **don't remove** the file with these embeddings because you will need them in the final project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authorization & Submission\n",
    "To submit assignment parts to Cousera platform, please, enter your e-mail and token into variables below. You can generate token on this programming assignment page. <b>Note:</b> Token expires 30 minutes after generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to submit these parts:\n",
      "Task Question2Vec: 0.01929389126598835\n",
      "-0.02872721292078495\n",
      "0.0460561104118824\n",
      "0.0852593332529068\n",
      "0.0243055559694767\n",
      "-0...\n",
      "Task HitsCount: 1.0\n",
      "0.5\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1....\n",
      "Task DCGScore: 1.0\n",
      "0.5\n",
      "0.8154648767857288\n",
      "0.5\n",
      "0.8154648767857288\n",
      "0.3333333333333333\n",
      "0.5436432511904858\n",
      "0.7103099178...\n",
      "Task W2VTokenizedRanks: 95\t94\t7\t9\t64\t37\t32\t93\t24\t100\t98\t17\t60\t6\t97\t49\t70\t38\t42\t96\t30\t21\t2\t65\t67\t45\t27\t26\t57\t62\t11\t88\t56\t66\t7...\n",
      "Task StarSpaceRanks: 80\t57\t78\t12\t3\t81\t37\t63\t61\t47\t49\t10\t58\t19\t85\t68\t17\t87\t55\t98\t77\t93\t23\t75\t90\t62\t73\t94\t29\t1\t65\t27\t91\t59\t...\n"
     ]
    }
   ],
   "source": [
    "STUDENT_EMAIL = 'karenye.psu@gmail.com'\n",
    "STUDENT_TOKEN = 'nRV2nALRnk9Cczc8'\n",
    "grader.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to submit these answers, run cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
